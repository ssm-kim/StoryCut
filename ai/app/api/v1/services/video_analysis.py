import os
import cv2
import numpy as np
import torch
from operator import itemgetter
from mmaction.apis import init_recognizer, inference_recognizer
from app.core.logger import logger
import asyncio
from concurrent.futures import ThreadPoolExecutor

# ì„¤ì •
config_file = './src/mmaction2/configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x8-100e_kinetics400-rgb.py'
checkpoint_file = './src/mmaction2/checkpoints/tsn_imagenet-pretrained-r50_8xb32-1x1x8-100e_kinetics400-rgb_20220906-2692d16c.pth'
label_file = './src/mmaction2/tools/data/kinetics/label_map_k400.txt'
tmp_dir = 'temp_clips'
os.makedirs(tmp_dir, exist_ok=True)

# ë¼ë²¨ ë¡œë”©
with open(label_file, 'r') as f:
    labels = [line.strip() for line in f]

# ìŠ¤ë ˆë“œ í’€ ìƒì„±
executor = ThreadPoolExecutor(max_workers=2)  # GPU ê²½í•© ë°©ì§€ë¥¼ ìœ„í•´ ì œí•œ

# í´ë¦½ ë¶„ì„ (ë™ê¸° í•¨ìˆ˜)
def _analyze_clip(model, temp_video, start_frame, end_frame, fps):
    try:
        pred_result = inference_recognizer(model, temp_video)
        pred_scores = pred_result.pred_score.tolist()
        score_tuples = tuple(zip(range(len(pred_scores)), pred_scores))
        score_sorted = sorted(score_tuples, key=itemgetter(1), reverse=True)
        top2_label = score_sorted[:2]
        results = [(labels[k[0]], k[1]) for k in top2_label]
        time_sec = (start_frame / fps, end_frame / fps)
        return (time_sec, results)
    except Exception as e:
        logger.error(f"[Analysis] í´ë¦½ ë¶„ì„ ì˜¤ë¥˜ ({temp_video}): {str(e)}")
        return None

# ë¹„ë™ê¸° ë˜í¼
async def _analyze_clip_async(model, temp_video, start_frame, end_frame, fps):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(
        executor, _analyze_clip, model, temp_video, start_frame, end_frame, fps
    )

# ë©”ì¸ íŒŒì´í”„ë¼ì¸
async def run_analysis_pipeline(video_path: str) -> list:
    logger.info(f"[Analysis] ì˜ìƒ ë¶„ì„ ì‹œì‘ â†’ {video_path}")

    try:
        model = init_recognizer(config_file, checkpoint_file, device='cuda:0')
        logger.info("[Analysis] ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        logger.info(f"[Analysis] FPS: {fps}, ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")

        window_sec = 3
        window_size = int(window_sec * fps)
        results = []

        for start_frame in range(0, total_frames, window_size):
            end_frame = min(start_frame + window_size, total_frames)
            frames = []

            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
            for _ in range(start_frame, end_frame):
                ret, frame = cap.read()
                if not ret:
                    break
                frames.append(frame)

            if not frames:
                logger.warning(f"[Analysis] í´ë¦½ í”„ë ˆì„ ì—†ìŒ â†’ êµ¬ê°„: {start_frame}~{end_frame}")
                continue

            temp_video = os.path.join(tmp_dir, f'temp_{start_frame}.mp4')
            h, w, _ = frames[0].shape
            writer = cv2.VideoWriter(temp_video, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))
            for f in frames:
                writer.write(f)
            writer.release()
            logger.info(f"[Analysis] ì„ì‹œ í´ë¦½ ì €ì¥ ì™„ë£Œ â†’ {temp_video}")

            # ğŸ”¥ ë¶„ì„ í›„ ê²°ê³¼ ë°”ë¡œ ì €ì¥ (ë¹„ë™ê¸° ì‹¤í–‰)
            result = await _analyze_clip_async(model, temp_video, start_frame, end_frame, fps)
            if result:
                results.append(result)

            # í´ë¦½ ì‚­ì œ
            os.remove(temp_video)
            logger.info(f"[Analysis] ì„ì‹œ í´ë¦½ ì‚­ì œ ì™„ë£Œ â†’ {temp_video}")

        cap.release()
        del model
        torch.cuda.empty_cache()
        logger.info("[Analysis] ëª¨ë¸ í•´ì œ ë° GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")

        return results

    except Exception as e:
        logger.error(f"[Analysis] ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise
